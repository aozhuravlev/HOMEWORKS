**Эластичная сеть** (Elastic Net) — это модель линейной регрессии, которая объединяет два типа регуляризации: **L1 (LASSO)** и **L2 (Ridge)**. Эластичная сеть была создана, чтобы объединить преимущества обоих методов и устранить их недостатки.

### Формула:

Модель минимизирует следующую функцию:

$$
\text{Elastic Net} \text{ минимизирует } \left( \sum (y_i - X_i \beta)^2 + \lambda_1 \sum |\beta_j| + \lambda_2 \sum \beta_j^2 \right)
$$

Где:
- $\lambda_1$ — коэффициент регуляризации для L1 (LASSO),
- $\lambda_2$ — коэффициент регуляризации для L2 (Ridge).

Эластичная сеть применяет одновременно L1 и L2 штрафы на коэффициенты модели.

### Преимущества эластичной сети:

1. **Решение проблемы мультиколлинеарности:**
   Если признаки сильно коррелируют между собой, гребневая регуляризация (L2) хорошо справляется с этой проблемой, сжимая коэффициенты, но не зануляя их.

2. **Отбор признаков:**
   LASSO (L1) зануляет коэффициенты наименее значимых признаков, что помогает автоматически выбирать важные признаки. Эластичная сеть наследует это свойство и может занулять коэффициенты для наименее полезных переменных.

3. **Гибкость:**
   Эластичная сеть сочетает преимущества обоих методов и может более точно настроить регуляризацию. Когда LASSO зануляет слишком много коэффициентов или Ridge не может убрать ненужные признаки, эластичная сеть помогает найти компромисс.

4. **Устойчивость при большом количестве признаков:**
   Эластичная сеть особенно полезна, если число признаков значительно превышает количество наблюдений (признаков больше, чем данных). В таких случаях комбинация L1 и L2 регуляризации помогает лучше справляться с переобучением.

### Пример с использованием эластичной сети

```python
import numpy as np
import pandas as pd
from sklearn.linear_model import ElasticNet
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# Пример данных
data = pd.DataFrame({
    'GrLivArea': [1000, 1500, 1800, 2400, 3000, 3600],
    'GarageArea': [200, 300, 350, 450, 500, 600],
    'SalePrice': [150000, 200000, 220000, 300000, 360000, 400000]
})

X = data[['GrLivArea', 'GarageArea']]
y = data['SalePrice']

# Разделение данных на тренировочные и тестовые
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Обучение модели ElasticNet
elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)  # l1_ratio регулирует соотношение между L1 и L2
elastic_net.fit(X_train, y_train)

# Предсказания
y_pred = elastic_net.predict(X_test)

# Оценка точности (RMSE)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print(f"RMSE Elastic Net: {rmse}")

# Коэффициенты модели
print(f"Коэффициенты Elastic Net: {elastic_net.coef_}")
print(f"Свободный член (intercept): {elastic_net.intercept_}")

# Построение графика предсказанных vs фактических значений
plt.scatter(y_test, y_pred)
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')
plt.xlabel('Фактические значения')
plt.ylabel('Предсказанные значения')
plt.title('Elastic Net: Предсказанные vs Фактические значения')
plt.show()
```

### Подбор параметров регуляризации:

Для эластичной сети мы можем использовать два гиперпараметра:
- **alpha** — контролирует общий уровень регуляризации,
- **l1_ratio** — определяет баланс между L1 (LASSO) и L2 (Ridge) регуляризацией. Когда **l1_ratio = 0**, модель превращается в чисто гребневую регрессию (Ridge). Когда **l1_ratio = 1**, это LASSO.

Для подбора оптимальных параметров можно использовать GridSearchCV.

```python
from sklearn.model_selection import GridSearchCV

# Подбор параметров alpha и l1_ratio
param_grid = {'alpha': np.linspace(0.01, 1, 5), 'l1_ratio': np.linspace(0, 1, 5)}
elastic_net_cv = GridSearchCV(ElasticNet(), param_grid, cv=5)
elastic_net_cv.fit(X_train, y_train)

# Оптимальные параметры
print(f"Оптимальные параметры: {elastic_net_cv.best_params_}")
```

### Преимущества эластичной сети в сравнении с LASSO и Ridge:
- Если LASSO зануляет слишком много коэффициентов, Elastic Net может избежать этого за счет частичной L2 регуляризации.
- Если Ridge не справляется с отбором признаков, Elastic Net добавляет L1 штраф, который зануляет незначимые признаки.
- Подходит для задач с высокой мультиколлинеарностью и большим числом признаков.

### Когда использовать эластичную сеть?
Эластичную сеть следует применять, если у тебя есть данные с множеством признаков, многие из которых могут быть коррелированы между собой, и тебе нужно одновременно отбирать признаки и справляться с мультиколлинеарностью.