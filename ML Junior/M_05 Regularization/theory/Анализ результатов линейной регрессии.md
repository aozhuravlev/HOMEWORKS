Перед тем как перейти к регуляризации, важно уметь анализировать результаты линейной регрессии. Рассмотрим основные понятия, которые необходимо учитывать.

### Гомоскедастичность и гетероскедастичность

- **Гомоскедастичность** — это когда дисперсия ошибок (остатков) одинакова для всех наблюдений. В идеальной линейной модели мы хотим, чтобы ошибки были равномерно распределены.
- **Гетероскедастичность** — это когда дисперсия ошибок изменяется в зависимости от значений независимых переменных. Это может указывать на неправильную спецификацию модели.

#### Пример проверки гетероскедастичности

```python
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Пример данных
data = pd.DataFrame({
    'GrLivArea': [1000, 1500, 1800, 2400, 3000, 3600],
    'SalePrice': [150000, 200000, 220000, 300000, 360000, 400000]
})

X = data[['GrLivArea']]
y = data['SalePrice']

# Разделение на тренировочные и тестовые данные
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Обучение модели
model = LinearRegression()
model.fit(X_train, y_train)

# Предсказания на тестовых данных
y_pred = model.predict(X_test)

# Построение графика остатков
residuals = y_test - y_pred
plt.scatter(y_pred, residuals)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Предсказанные значения')
plt.ylabel('Остатки')
plt.title('График остатков')
plt.show()
```

Если остатки случайно разбросаны вокруг горизонтальной линии (гомоскедастичность), модель достаточно хорошо специфицирована.

### Остатки модели

Остатки — это разница между предсказанными и фактическими значениями. Мы анализируем их, чтобы понять, насколько модель отклоняется от реальных данных.

**Пример кода для анализа остатков:**

```python
# Вывод остатков
residuals = y_test - y_pred
print("Остатки:\n", residuals)
```

### Коэффициент детерминации (R²)

**R²** — это мера, показывающая, какую долю вариации зависимой переменной объясняет модель. Чем ближе R² к 1, тем лучше модель объясняет данные.

**Пример расчета R²:**

```python
r2 = model.score(X_test, y_test)
print(f"Коэффициент детерминации R²: {r2}")
```
