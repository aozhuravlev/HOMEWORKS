{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- logarithm\n",
    "- feat_eng\n",
    "- target_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import funcs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ydata_profiling import ProfileReport\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import (\n",
    "    ExtraTreesRegressor,\n",
    "    RandomForestRegressor,\n",
    "    VotingRegressor,\n",
    ")\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Id      800 non-null    int64  \n",
      " 1   C       800 non-null    float64\n",
      " 2   BFS     800 non-null    float64\n",
      " 3   FA      800 non-null    float64\n",
      " 4   W       800 non-null    float64\n",
      " 5   SP      800 non-null    float64\n",
      " 6   Ag      800 non-null    float64\n",
      " 7   Af      800 non-null    float64\n",
      " 8   t       800 non-null    int64  \n",
      " 9   target  800 non-null    float64\n",
      "dtypes: float64(8), int64(2)\n",
      "memory usage: 62.6 KB\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "# df_train = df_train.drop(['Id'], axis=1)\n",
    "# df_test = df_test.drop(['Id'], axis=1)\n",
    "df_train.rename(\n",
    "    columns={\n",
    "        \"Strength\": \"target\",\n",
    "        \"Superplasticizer\": \"SP\",\n",
    "        \"Fly Ash\": \"FA\",\n",
    "        \"Water\": \"W\",\n",
    "        \"Coarse Aggregate\": \"Ag\",\n",
    "        \"Fine Aggregate\": \"Af\",\n",
    "        \"Blast Furnace Slag\": \"BFS\",\n",
    "        \"Cement\": \"C\",\n",
    "        \"Age\": \"t\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "df_train.info()\n",
    "# df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Id - идентификатор состава.\n",
    "- CementComponent - количество цемента в смеси.\n",
    "- BlastFurnaceSlag - количество доменного шлака в смеси.\n",
    "- FlyAshComponent - количество зольной пыли в смеси.\n",
    "- WaterComponent - количество воды в смеси.\n",
    "- SuperplasticizerComponent - количество суперпластификатора в смеси.\n",
    "- CoarseAggregateComponent - количество заполнителя с грубой фракцией в смеси.\n",
    "- FineAggregateComponent - количество заполнителя с мелкой фракцией в смеси.\n",
    "- Age - время высыхания в днях.\n",
    "- Strength - прочность получившегося бетона (Целевая переменная)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 7, 14, 28, 56, 90, 91, 100, 120, 180, 270, 360, 365]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df_train.t.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 7, 14, 28, 56, 90, 120, 180, 270, 365]\n",
      "t\n",
      "28     321\n",
      "7      102\n",
      "3      100\n",
      "56      73\n",
      "90      67\n",
      "14      49\n",
      "120     42\n",
      "180     19\n",
      "365     16\n",
      "270     11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_train.loc[df_train.t == 360, \"t\"] = 365\n",
    "df_train.loc[df_train.t == 91, \"t\"] = 90\n",
    "df_train.loc[df_train.t.isin([100, 120]), \"t\"] = 120\n",
    "df_train.loc[df_train.t == 1, \"t\"] = 3\n",
    "# df_train.loc[df_train.t.isin([270, 365]), \"t\"] = 180\n",
    "print(sorted(df_train.t.unique()))\n",
    "print(df_train.t.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'C', 'BFS', 'FA', 'W', 'SP', 'Ag', 'Af', 't', 'target'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = df_train[df_train.drop(columns=[\"target\", \"t\", \"Id\"]).duplicated()]\n",
    "len(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_22416\\3301022168.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_flat = data_grouped.apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>C</th>\n",
       "      <th>BFS</th>\n",
       "      <th>FA</th>\n",
       "      <th>W</th>\n",
       "      <th>SP</th>\n",
       "      <th>Ag</th>\n",
       "      <th>Af</th>\n",
       "      <th>Str_3</th>\n",
       "      <th>Str_7</th>\n",
       "      <th>Str_14</th>\n",
       "      <th>Str_28</th>\n",
       "      <th>Str_56</th>\n",
       "      <th>Str_90</th>\n",
       "      <th>Str_120</th>\n",
       "      <th>Str_180</th>\n",
       "      <th>Str_270</th>\n",
       "      <th>Str_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>887.0</td>\n",
       "      <td>942.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108.3</td>\n",
       "      <td>162.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>203.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>938.2</td>\n",
       "      <td>849.0</td>\n",
       "      <td>2.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>116.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>909.8</td>\n",
       "      <td>891.9</td>\n",
       "      <td>6.28</td>\n",
       "      <td>10.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>122.6</td>\n",
       "      <td>183.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>203.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>958.2</td>\n",
       "      <td>800.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>132.0</td>\n",
       "      <td>206.5</td>\n",
       "      <td>160.9</td>\n",
       "      <td>178.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>866.9</td>\n",
       "      <td>735.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>358</td>\n",
       "      <td>528.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>920.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>359</td>\n",
       "      <td>531.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.8</td>\n",
       "      <td>28.2</td>\n",
       "      <td>852.1</td>\n",
       "      <td>893.7</td>\n",
       "      <td>41.30</td>\n",
       "      <td>46.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.40</td>\n",
       "      <td>58.8</td>\n",
       "      <td>59.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>360</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>361</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>362</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>613.0</td>\n",
       "      <td>41.64</td>\n",
       "      <td>52.61</td>\n",
       "      <td>59.76</td>\n",
       "      <td>67.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.62</td>\n",
       "      <td>74.17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index      C    BFS     FA      W    SP      Ag     Af  Str_3  Str_7  \\\n",
       "0        0  102.0  153.0    0.0  192.0   0.0   887.0  942.0    NaN   7.68   \n",
       "1        1  108.3  162.4    0.0  203.5   0.0   938.2  849.0   2.33    NaN   \n",
       "2        2  116.0  173.0    0.0  192.0   0.0   909.8  891.9   6.28  10.09   \n",
       "3        3  122.6  183.9    0.0  203.5   0.0   958.2  800.1    NaN  10.35   \n",
       "4        4  132.0  206.5  160.9  178.9   5.5   866.9  735.6    NaN    NaN   \n",
       "..     ...    ...    ...    ...    ...   ...     ...    ...    ...    ...   \n",
       "358    358  528.0    0.0    0.0  185.0   6.9   920.0  720.0    NaN    NaN   \n",
       "359    359  531.3    0.0    0.0  141.8  28.2   852.1  893.7  41.30  46.90   \n",
       "360    360  540.0    0.0    0.0  162.0   2.5  1040.0  676.0    NaN    NaN   \n",
       "361    361  540.0    0.0    0.0  162.0   2.5  1055.0  676.0    NaN    NaN   \n",
       "362    362  540.0    0.0    0.0  173.0   0.0  1125.0  613.0  41.64  52.61   \n",
       "\n",
       "     Str_14  Str_28  Str_56  Str_90  Str_120  Str_180  Str_270  Str_365  \n",
       "0       NaN   17.28     NaN     NaN      NaN      NaN      NaN      NaN  \n",
       "1       NaN   20.59     NaN     NaN      NaN      NaN      NaN      NaN  \n",
       "2       NaN   22.35     NaN   31.02      NaN      NaN      NaN      NaN  \n",
       "3       NaN   24.29     NaN   33.19      NaN      NaN      NaN      NaN  \n",
       "4       NaN   33.31     NaN     NaN      NaN      NaN      NaN      NaN  \n",
       "..      ...     ...     ...     ...      ...      ...      ...      ...  \n",
       "358     NaN   56.83     NaN     NaN      NaN      NaN      NaN      NaN  \n",
       "359     NaN   56.40    58.8   59.20      NaN      NaN      NaN      NaN  \n",
       "360     NaN   79.99     NaN     NaN      NaN      NaN      NaN      NaN  \n",
       "361     NaN   61.89     NaN     NaN      NaN      NaN      NaN      NaN  \n",
       "362   59.76   67.31     NaN   69.66      NaN    71.62    74.17      NaN  \n",
       "\n",
       "[363 rows x 18 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Предположим, что данные содержат следующие столбцы:\n",
    "# 'Id', 'CementComponent', 'BlastFurnaceSlag', 'FlyAshComponent',\n",
    "# 'WaterComponent', 'SuperplasticizerComponent', 'CoarseAggregateComponent',\n",
    "# 'FineAggregateComponent', 'Age', 'Strength'\n",
    "\n",
    "# Убираем дублирующиеся строки состава смеси, кроме 'Age' и 'Strength'\n",
    "data_grouped = df_train.groupby(\n",
    "    [\"C\", \"BFS\", \"FA\", \"W\", \"SP\", \"Ag\", \"Af\"], as_index=False\n",
    ")\n",
    "\n",
    "# Создаем новый \"выпрямленный\" DataFrame\n",
    "df_flat = data_grouped.apply(\n",
    "    lambda group: pd.Series(\n",
    "        {\n",
    "            age: (\n",
    "                group[group[\"t\"] == age][\"target\"].values[0]\n",
    "                if age in group[\"t\"].values\n",
    "                else None\n",
    "            )\n",
    "            for age in sorted(df_train[\"t\"].unique())\n",
    "        }\n",
    "    )\n",
    ").reset_index()\n",
    "\n",
    "# Добавляем названия для столбцов\n",
    "df_flat.columns = list(df_flat.columns[: -len(df_train[\"t\"].unique())]) + [\n",
    "    f\"Str_{age}\" for age in sorted(df_train[\"t\"].unique())\n",
    "]\n",
    "\n",
    "df_flat.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>BFS</th>\n",
       "      <th>FA</th>\n",
       "      <th>W</th>\n",
       "      <th>SP</th>\n",
       "      <th>Ag</th>\n",
       "      <th>Af</th>\n",
       "      <th>Str_3</th>\n",
       "      <th>Str_7</th>\n",
       "      <th>Str_14</th>\n",
       "      <th>Str_28</th>\n",
       "      <th>Str_56</th>\n",
       "      <th>Str_90</th>\n",
       "      <th>Str_120</th>\n",
       "      <th>Str_180</th>\n",
       "      <th>Str_270</th>\n",
       "      <th>Str_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>135.7</td>\n",
       "      <td>203.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1076.2</td>\n",
       "      <td>759.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>139.6</td>\n",
       "      <td>209.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>806.9</td>\n",
       "      <td>8.06</td>\n",
       "      <td>14.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>153.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>888.0</td>\n",
       "      <td>943.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>157.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>935.4</td>\n",
       "      <td>781.2</td>\n",
       "      <td>9.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>165.0</td>\n",
       "      <td>128.5</td>\n",
       "      <td>132.1</td>\n",
       "      <td>175.1</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1005.8</td>\n",
       "      <td>746.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C    BFS     FA      W   SP      Ag     Af  Str_3  Str_7  Str_14  \\\n",
       "11  135.7  203.5    0.0  185.7  0.0  1076.2  759.3    NaN   7.51     NaN   \n",
       "13  139.6  209.4    0.0  192.0  0.0  1047.0  806.9   8.06  14.59     NaN   \n",
       "52  153.0  102.0    0.0  192.0  0.0   888.0  943.1    NaN   8.37     NaN   \n",
       "69  157.0  236.0    0.0  192.0  0.0   935.4  781.2   9.69    NaN     NaN   \n",
       "87  165.0  128.5  132.1  175.1  8.1  1005.8  746.6    NaN    NaN     NaN   \n",
       "\n",
       "    Str_28  Str_56  Str_90  Str_120  Str_180  Str_270  Str_365  \n",
       "11     NaN     NaN     NaN      NaN      NaN      NaN      NaN  \n",
       "13     NaN     NaN   39.36      NaN    44.21      NaN     44.7  \n",
       "52     NaN     NaN   26.32      NaN      NaN      NaN      NaN  \n",
       "69     NaN     NaN   43.38      NaN      NaN      NaN      NaN  \n",
       "87     NaN   53.72     NaN    55.02      NaN      NaN      NaN  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flat[df_flat.Str_28.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [col for col in df_flat.columns if 'Strength' in col]\n",
    "df_flat.drop(columns=['index'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 363 entries, 0 to 362\n",
      "Data columns (total 17 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   C        363 non-null    float64\n",
      " 1   BFS      363 non-null    float64\n",
      " 2   FA       363 non-null    float64\n",
      " 3   W        363 non-null    float64\n",
      " 4   SP       363 non-null    float64\n",
      " 5   Ag       363 non-null    float64\n",
      " 6   Af       363 non-null    float64\n",
      " 7   Str_3    94 non-null     float64\n",
      " 8   Str_7    97 non-null     float64\n",
      " 9   Str_14   49 non-null     float64\n",
      " 10  Str_28   312 non-null    float64\n",
      " 11  Str_56   69 non-null     float64\n",
      " 12  Str_90   63 non-null     float64\n",
      " 13  Str_120  42 non-null     float64\n",
      " 14  Str_180  19 non-null     float64\n",
      " 15  Str_270  11 non-null     float64\n",
      " 16  Str_365  16 non-null     float64\n",
      "dtypes: float64(17)\n",
      "memory usage: 48.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_flat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [col for col in df_flat.columns if 'Str' in col]\n",
    "X_fl = df_flat.drop(columns=target_cols)\n",
    "y_fl = df_flat[target_cols]\n",
    "# y_fl.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 363 entries, 0 to 362\n",
      "Data columns (total 10 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Str_3    94 non-null     float64\n",
      " 1   Str_7    97 non-null     float64\n",
      " 2   Str_14   49 non-null     float64\n",
      " 3   Str_28   312 non-null    float64\n",
      " 4   Str_56   69 non-null     float64\n",
      " 5   Str_90   63 non-null     float64\n",
      " 6   Str_120  42 non-null     float64\n",
      " 7   Str_180  19 non-null     float64\n",
      " 8   Str_270  11 non-null     float64\n",
      " 9   Str_365  16 non-null     float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 28.5 KB\n"
     ]
    }
   ],
   "source": [
    "y_fl.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_fl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\skillbox\\HOMEWORKS\\ML Junior\\M_19 - Kaggle\\regression\\Kaggle_regr.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/skillbox/HOMEWORKS/ML%20Junior/M_19%20-%20Kaggle/regression/Kaggle_regr.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m y_fl\u001b[39m.\u001b[39mhead(\u001b[39m30\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_fl' is not defined"
     ]
    }
   ],
   "source": [
    "y_fl.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #14 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #1 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #11 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #1 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #11 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #1 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #11 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #1 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #11 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n",
      "Got unsafe target value = nan at object #0 of dataset learn\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\User\\skillbox\\HOMEWORKS\\HWs\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\User\\skillbox\\HOMEWORKS\\HWs\\Lib\\site-packages\\catboost\\core.py\", line 5873, in fit\n    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\User\\skillbox\\HOMEWORKS\\HWs\\Lib\\site-packages\\catboost\\core.py\", line 2410, in _fit\n    self._train(\n  File \"c:\\Users\\User\\skillbox\\HOMEWORKS\\HWs\\Lib\\site-packages\\catboost\\core.py\", line 1790, in _train\n    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n  File \"_catboost.pyx\", line 5017, in _catboost._CatBoost._train\n  File \"_catboost.pyx\", line 5066, in _catboost._CatBoost._train\n_catboost.CatBoostError: catboost/libs/metrics/metric.cpp:6951: metric/loss-function MultiRMSE do not allows nan value on target\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\skillbox\\HOMEWORKS\\ML Junior\\M_19 - Kaggle\\regression\\Kaggle_regr.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/skillbox/HOMEWORKS/ML%20Junior/M_19%20-%20Kaggle/regression/Kaggle_regr.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cb_fl \u001b[39m=\u001b[39m CatBoostRegressor(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/skillbox/HOMEWORKS/ML%20Junior/M_19%20-%20Kaggle/regression/Kaggle_regr.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     iterations\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/skillbox/HOMEWORKS/ML%20Junior/M_19%20-%20Kaggle/regression/Kaggle_regr.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39m\u001b[39m.01\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/skillbox/HOMEWORKS/ML%20Junior/M_19%20-%20Kaggle/regression/Kaggle_regr.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     loss_function\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMultiRMSE\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/skillbox/HOMEWORKS/ML%20Junior/M_19%20-%20Kaggle/regression/Kaggle_regr.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/skillbox/HOMEWORKS/ML%20Junior/M_19%20-%20Kaggle/regression/Kaggle_regr.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m funcs\u001b[39m.\u001b[39;49mget_cv_rmse(cb_fl, X_fl, y_fl)\n",
      "File \u001b[1;32mc:\\Users\\User\\skillbox\\HOMEWORKS\\ML Junior\\M_19 - Kaggle\\regression\\funcs.py:20\u001b[0m, in \u001b[0;36mget_cv_rmse\u001b[1;34m(model, X, y)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_cv_rmse\u001b[39m(model, X, y):\n\u001b[0;32m     19\u001b[0m     rmse \u001b[39m=\u001b[39m (\n\u001b[1;32m---> 20\u001b[0m         cross_val_score(model, X, y, cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, scoring\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mneg_root_mean_squared_error\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mmean()\n\u001b[0;32m     21\u001b[0m         \u001b[39m*\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     22\u001b[0m     )\n\u001b[0;32m     23\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCV RMSE: \u001b[39m\u001b[39m{\u001b[39;00mrmse\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User\\skillbox\\HOMEWORKS\\HWs\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\skillbox\\HOMEWORKS\\HWs\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    710\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 712\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    713\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    714\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    715\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    716\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    717\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    718\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    719\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    720\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    721\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    722\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    723\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    724\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    725\u001b[0m )\n\u001b[0;32m    726\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\skillbox\\HOMEWORKS\\HWs\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\skillbox\\HOMEWORKS\\HWs\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:443\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    422\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m    423\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    424\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    425\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m indices\n\u001b[0;32m    441\u001b[0m )\n\u001b[1;32m--> 443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    445\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32mc:\\Users\\User\\skillbox\\HOMEWORKS\\HWs\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    523\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    524\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[1;32m--> 529\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    533\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\User\\skillbox\\HOMEWORKS\\HWs\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\User\\skillbox\\HOMEWORKS\\HWs\\Lib\\site-packages\\catboost\\core.py\", line 5873, in fit\n    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\User\\skillbox\\HOMEWORKS\\HWs\\Lib\\site-packages\\catboost\\core.py\", line 2410, in _fit\n    self._train(\n  File \"c:\\Users\\User\\skillbox\\HOMEWORKS\\HWs\\Lib\\site-packages\\catboost\\core.py\", line 1790, in _train\n    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n  File \"_catboost.pyx\", line 5017, in _catboost._CatBoost._train\n  File \"_catboost.pyx\", line 5066, in _catboost._CatBoost._train\n_catboost.CatBoostError: catboost/libs/metrics/metric.cpp:6951: metric/loss-function MultiRMSE do not allows nan value on target\n"
     ]
    }
   ],
   "source": [
    "# cb_fl = CatBoostRegressor(\n",
    "#     iterations=1000,\n",
    "#     learning_rate=.01,\n",
    "#     depth=5,\n",
    "#     random_seed=137,\n",
    "#     eval_metric='MultiRMSE',\n",
    "#     logging_level='Silent',\n",
    "#     loss_function='MultiRMSE',\n",
    "# )\n",
    "# funcs.get_cv_rmse(cb_fl, X_fl, y_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 7, 14, 28, 56, 90, 91, 100, 180, 270, 360, 365]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df_test.t.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report = ProfileReport(df_train)\n",
    "# report.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# lof = LocalOutlierFactor(n_neighbors=20)\n",
    "# outliers = lof.fit_predict(df_train[['Age']])\n",
    "# filtered_df = df_train[outliers == 1]\n",
    "# filtered_df.shape\n",
    "\n",
    "# X = filtered_df.drop(columns=[\"target\"])\n",
    "# y = filtered_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[\"Age_Category\"] = pd.cut(\n",
    "#     df_train[\"t\"], bins=[0, 7, 28, 90, 180, 365], labels=[1, 2, 3, 4, 5]\n",
    "# ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcs.show_box_plot(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=[\"target\"])\n",
    "y = df_train[\"target\"]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=137\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE: 4.487866246300864\n"
     ]
    }
   ],
   "source": [
    "cb = CatBoostRegressor(\n",
    "    iterations=10000,\n",
    "    learning_rate=.01,\n",
    "    # cat_features=['t'],\n",
    "    depth=5,\n",
    "    random_seed=137,\n",
    "    eval_metric='RMSE',\n",
    "    logging_level='Silent',\n",
    "    loss_function='RMSE',\n",
    ")\n",
    "funcs.get_cv_rmse(cb, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score for VotingRegressor: 4.38\n"
     ]
    }
   ],
   "source": [
    "cb = CatBoostRegressor(\n",
    "    iterations=10000,\n",
    "    learning_rate=.01,\n",
    "    depth=5,\n",
    "    random_seed=137,\n",
    "    eval_metric='RMSE',\n",
    "    logging_level='Silent',\n",
    ")\n",
    "# funcs.get_cv_rmse(cb, X_log, y)\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    random_state=137,\n",
    "    max_depth=5,\n",
    "    learning_rate=.01,\n",
    "    n_estimators=5000\n",
    ")\n",
    "# funcs.get_cv_rmse(xgb, X_log, y)\n",
    "\n",
    "lgb = LGBMRegressor(\n",
    "    random_state=137,\n",
    "    verbose=-1,\n",
    "    n_estimators=5500,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=12\n",
    ")\n",
    "# funcs.get_cv_rmse(lgb, X_log, y)\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    random_state=137,\n",
    "    n_jobs=-1,\n",
    "    n_estimators=5500,\n",
    "    max_features=\"log2\",\n",
    ")\n",
    "# funcs.get_cv_rmse(rf, X_log, y)\n",
    "\n",
    "xt = ExtraTreesRegressor(\n",
    "    random_state=137,\n",
    "    n_jobs=-1,\n",
    "    n_estimators=5500,\n",
    ")\n",
    "# funcs.get_cv_rmse(xt, X_log, y)\n",
    "\n",
    "vote = VotingRegressor(\n",
    "    estimators=[\n",
    "        ('xt', xt),\n",
    "        ('rf', rf),\n",
    "        ('xgb', xgb),\n",
    "        ('cb', cb),\n",
    "        ('lgb', lgb),\n",
    "    ],\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "funcs.get_rmse_score([vote], X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vote.fit(X, y)\n",
    "# y_pred = vote.predict(df_test)\n",
    "# y_pred_df = pd.DataFrame({'Id': range(0, len(y_pred)), 'Strength': np.round(y_pred, 1)})\n",
    "# y_pred_df.to_csv('y_pred_regression.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_exp = df_train.copy()\n",
    "# print(len(df_exp))\n",
    "# df_exp.drop(columns=[\"target\", \"t\"], inplace=True)\n",
    "# duplicates = df_exp[df_exp.duplicated()]\n",
    "# len(duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_exp = df_test.copy()\n",
    "\n",
    "df_test_exp.drop(columns=[\"t\", \"Id\"], inplace=True)\n",
    "duplicates_test = df_test_exp[df_test_exp.duplicated()]\n",
    "len(duplicates_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE   : 4.44\n",
      "MAPE      : 0.12\n"
     ]
    }
   ],
   "source": [
    "# X_fe = funcs.engineer_features(X)\n",
    "# # X_test_fe = funcs.engineer_features(X_test_log)\n",
    "\n",
    "# cb_fe = CatBoostRegressor(\n",
    "#     iterations=10000,\n",
    "#     learning_rate=.01,\n",
    "#     depth=5,\n",
    "#     random_seed=137,\n",
    "#     eval_metric='RMSE',\n",
    "#     logging_level='Silent',\n",
    "# )\n",
    "# funcs.get_cv_rmse(cb_fe, X_fe, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score for VotingRegressor: 4.54\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cb_fe = CatBoostRegressor(\n",
    "    iterations=400,\n",
    "    learning_rate=.5,\n",
    "    depth=4,\n",
    "    random_seed=137,\n",
    "    eval_metric='RMSE',\n",
    "    logging_level='Silent',\n",
    ")\n",
    "\n",
    "xgb_fe = XGBRegressor(\n",
    "    random_state=137,\n",
    "    max_depth=5,\n",
    "    learning_rate=.09,\n",
    "    n_estimators=500\n",
    ")\n",
    "\n",
    "lgb_fe = LGBMRegressor(\n",
    "    random_state=137,\n",
    "    verbose=-1,\n",
    "    n_estimators=550,\n",
    "    learning_rate=0.08,\n",
    "    max_depth=12\n",
    ")\n",
    "\n",
    "rf_fe = RandomForestRegressor(\n",
    "    random_state=137,\n",
    "    n_jobs=-1,\n",
    "    n_estimators=1500,\n",
    "    max_features=\"log2\",\n",
    ")\n",
    "\n",
    "xt_fe = ExtraTreesRegressor(\n",
    "    random_state=137,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "vote_fe = VotingRegressor(\n",
    "    estimators=[\n",
    "        ('xt_fe', xt_fe),\n",
    "        ('rf_fe', rf_fe),\n",
    "        ('xgb_fe', xgb_fe),\n",
    "        ('cb_fe', cb_fe),\n",
    "        ('lgb_fe', lgb_fe),\n",
    "    ],\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "\n",
    "funcs.get_rmse_score([vote_fe], X_fe, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HWs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
