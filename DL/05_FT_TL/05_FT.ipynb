{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import open_clip\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import f1_score\n",
    "import pytorch_lightning as pl\n",
    "from seed import seed_everything\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(137)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 8\n",
    "LR = 0.001\n",
    "DR = 0.2\n",
    "EPOCHS = 10\n",
    "NUM_CLASSES = 10\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_size = (224, 224) \n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize(image_size),  # Изменение размера\n",
    "#     transforms.ToTensor()           # Преобразование в тензор\n",
    "# ])\n",
    "\n",
    "# # Датасет без нормализации\n",
    "# dataset = datasets.ImageFolder(root=\"./data/train/\", transform=transform)\n",
    "# loader = DataLoader(dataset, batch_size=128, shuffle=False, num_workers=8, persistent_workers=True)\n",
    "\n",
    "# # Инициализируем тензоры для хранения сумм и квадратов сумм\n",
    "# mean = torch.zeros(3)\n",
    "# std = torch.zeros(3)\n",
    "# total_images = 0\n",
    "\n",
    "# for images, _ in loader:\n",
    "#     # Количество изображений в текущем батче\n",
    "#     batch_size = images.size(0)\n",
    "#     # Суммируем значения по каналам\n",
    "#     mean += torch.mean(images, dim=[0, 2, 3]) * batch_size\n",
    "#     # Суммируем квадраты значений по каналам\n",
    "#     std += torch.std(images, dim=[0, 2, 3]) * batch_size\n",
    "#     # Общее количество изображений\n",
    "#     total_images += batch_size\n",
    "\n",
    "# # Усредняем по всему датасету\n",
    "# mean /= total_images\n",
    "# std /= total_images\n",
    "\n",
    "# print(\"Mean:\", mean.numpy()) # Mean: [0.48012924 0.4843966  0.49254295]\n",
    "# print(\"Std:\", std.numpy()) # Std: [0.2613408 0.263237  0.269442 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5645/191347543.py:23: UserWarning: Argument(s) 'max_holes, max_height, max_width, mask_fill_value' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(max_holes=1, max_height=10, max_width=12, mask_fill_value=0, p=0.5),\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Функция-обёртка для Albumentations\n",
    "class AlbumentationsTransform:\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, img):\n",
    "        try:\n",
    "            img = np.array(img)  # Преобразуем PIL.Image в numpy\n",
    "            augmented = self.transform(image=img)  # Передаём в albumentations\n",
    "            return augmented[\"image\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error in Albumentations transformation: {e}\")\n",
    "            return img  # Вернем изображение без изменений в случае ошибки\n",
    "\n",
    "\n",
    "# Определим преобразования с использованием albumentations\n",
    "transform_train = A.Compose([\n",
    "    A.HorizontalFlip(p=0.3),\n",
    "    A.Affine(scale=(0.7, 1.3), translate_percent=(0.1, 0.1), rotate=(-15, 15), p=0.5),\n",
    "    A.CoarseDropout(max_holes=1, max_height=10, max_width=12, mask_fill_value=0, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.HueSaturationValue(p=0.3),\n",
    "    A.RandomGamma(p=0.3),\n",
    "    A.Resize(width=224, height=224),\n",
    "    A.Normalize(mean=(0.4801, 0.4844, 0.4925), std=(0.261, 0.263, 0.269)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "transform_test = A.Compose([\n",
    "    A.Resize(width=224, height=224),\n",
    "    A.Normalize(mean=(0.4801, 0.4844, 0.4925), std=(0.261, 0.263, 0.269)),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=BATCH_SIZE, train_split=0.8):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_split = train_split\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "        \n",
    "    def setup(self, stage: str):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            full_dataset = datasets.ImageFolder(\n",
    "                root=\"./data/train/\",\n",
    "                transform=AlbumentationsTransform(transform_train)\n",
    "            )\n",
    "            train_size = int(self.train_split * len(full_dataset))\n",
    "            val_size = len(full_dataset) - train_size\n",
    "            self.train_dataset, self.val_dataset = random_split(\n",
    "                full_dataset, [train_size, val_size]\n",
    "            )\n",
    "\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.test_dataset = datasets.ImageFolder(\n",
    "                root=\"./data/test_upload/\",\n",
    "                transform=AlbumentationsTransform(transform_test)\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=True,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            persistent_workers=True,\n",
    "        ) if self.train_dataset else None\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=True,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            persistent_workers=True,\n",
    "        ) if self.val_dataset else None\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            persistent_workers=True,\n",
    "        ) if self.test_dataset else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BASE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import F1Score, Accuracy\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, stride=1, expansion=4, dropout_rate=DR\n",
    "    ):\n",
    "        super().__init__()\n",
    "        bottleneck_channels = out_channels // expansion\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, bottleneck_channels, kernel_size=1, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(bottleneck_channels)\n",
    "        self.dropout1 = nn.Dropout2d(p=dropout_rate)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            bottleneck_channels,\n",
    "            bottleneck_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(bottleneck_channels)\n",
    "        self.dropout2 = nn.Dropout2d(p=dropout_rate)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            bottleneck_channels, out_channels, kernel_size=1, bias=False\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        self.dropout3 = nn.Dropout2d(p=dropout_rate)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels, out_channels, kernel_size=1, stride=stride, bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout2(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.dropout3(out)\n",
    "\n",
    "        out += self.shortcut(residual)\n",
    "        return self.relu(out)\n",
    "\n",
    "\n",
    "class CarClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, learning_rate=LR, dropout_rate=DR):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.f1_score = F1Score(num_classes=num_classes, task=\"multiclass\")\n",
    "        # self.val_acc = Accuracy(num_classes=num_classes, task=\"multiclass\")\n",
    "\n",
    "        # Backbone with dropout\n",
    "        self.layer1 = BottleneckBlock(3, 64, stride=2, dropout_rate=dropout_rate)\n",
    "        self.layer2 = BottleneckBlock(64, 128, stride=2, dropout_rate=dropout_rate)\n",
    "        self.layer3 = BottleneckBlock(128, 256, stride=2, dropout_rate=dropout_rate)\n",
    "\n",
    "        # Classifier\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)  # Dropout перед полносвязным слоем\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)  # Применяем dropout перед классификацией\n",
    "        return self.fc(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.val_acc(preds, y)\n",
    "        f1 = self.f1_score(preds, y)\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_f1\", f1, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return {\"val_loss\": loss, \"val_f1\": f1}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": scheduler,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "\n",
    "# В основном скрипте обучения:\n",
    "def train_model():\n",
    "    # Инициализация wandb\n",
    "    wandb_logger = WandbLogger(project='car_classifier', log_model='all')\n",
    "    \n",
    "    # Создание модели\n",
    "    model = CarClassifier()\n",
    "\n",
    "    data_module = DataModule()\n",
    "    \n",
    "    # Создание тренера с wandb logger\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=10,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=3)],\n",
    "    )\n",
    "        \n",
    "    # Обучение модели\n",
    "    trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmoscowzhuravlev\u001b[0m (\u001b[33mmoscowzhuravlev-selfemployedalex\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250207_094934-bxhd1msw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier/runs/bxhd1msw' target=\"_blank\">lemon-jazz-11</a></strong> to <a href='https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier' target=\"_blank\">https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier/runs/bxhd1msw' target=\"_blank\">https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier/runs/bxhd1msw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | criterion | CrossEntropyLoss   | 0      | train\n",
      "1 | f1_score  | MulticlassF1Score  | 0      | train\n",
      "2 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "3 | layer1    | BottleneckBlock    | 3.9 K  | train\n",
      "4 | layer2    | BottleneckBlock    | 24.2 K | train\n",
      "5 | layer3    | BottleneckBlock    | 95.5 K | train\n",
      "6 | avgpool   | AdaptiveAvgPool2d  | 0      | train\n",
      "7 | flatten   | Flatten            | 0      | train\n",
      "8 | dropout   | Dropout            | 0      | train\n",
      "9 | fc        | Linear             | 2.6 K  | train\n",
      "---------------------------------------------------------\n",
      "126 K     Trainable params\n",
      "0         Non-trainable params\n",
      "126 K     Total params\n",
      "0.505     Total estimated model params size (MB)\n",
      "49        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92fe40ffe65416fbc7399f2b426625f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4b6a5d2c804ce49d682fe06c669ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('medium')\n",
    "train_model()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **FINE TUNED ViT-B-16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import open_clip\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import MulticlassF1Score, Accuracy\n",
    "\n",
    "class CarClassifierViT(pl.LightningModule):\n",
    "    def __init__(self, num_classes=10, lr=2e-4, freeze_backbone_epochs=2):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Загружаем предобученную модель\n",
    "        self.model, _, _ = open_clip.create_model_and_transforms(\"ViT-B-16\", pretrained=\"openai\")\n",
    "        self.model.visual.proj = None\n",
    "        \n",
    "        # Добавляем dropout и batch norm перед классификатором\n",
    "        embed_dim = self.model.visual.ln_post.normalized_shape[0]\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm1d(embed_dim),\n",
    "            nn.Linear(embed_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Инициализация весов классификатора\n",
    "        for m in self.classifier.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.f1_score = MulticlassF1Score(num_classes=num_classes, average=\"macro\")\n",
    "        self.acc = Accuracy(num_classes=num_classes, task=\"multiclass\")\n",
    "        self.lr = lr\n",
    "        self.freeze_backbone_epochs = freeze_backbone_epochs\n",
    "        \n",
    "        # Сразу замораживаем backbone\n",
    "        for param in self.model.visual.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.model.encode_image(x)\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        \n",
    "        # Добавляем L2 регуляризацию\n",
    "        l2_lambda = 1e-4\n",
    "        l2_norm = sum(p.pow(2.0).sum() for p in self.classifier.parameters())\n",
    "        loss = loss + l2_lambda * l2_norm\n",
    "        \n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.acc(preds, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        f1 = self.f1_score(preds, y)\n",
    "        acc = self.acc(preds, y)\n",
    "        \n",
    "        self.log(\"val_loss\", loss, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        self.log(\"val_f1\", f1, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Используем разные learning rate для разных слоев\n",
    "        params = [\n",
    "            {'params': self.classifier.parameters(), 'lr': self.lr}\n",
    "        ]\n",
    "        \n",
    "        optimizer = optim.AdamW(params, weight_decay=0.01)\n",
    "        \n",
    "        # Используем ReduceLROnPlateau вместо CosineAnnealing\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=2,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def on_train_epoch_start(self):\n",
    "        if self.current_epoch == self.freeze_backbone_epochs:\n",
    "            print(\"Unfreezing backbone...\")\n",
    "            for param in self.model.visual.parameters():\n",
    "                param.requires_grad = True\n",
    "            \n",
    "            # Получаем оптимизатор правильным способом\n",
    "            optimizer = self.trainer.optimizers[0]\n",
    "            optimizer.add_param_group({\n",
    "                \"params\": self.model.visual.parameters(),\n",
    "                \"lr\": self.lr * 0.1\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Инициализация wandb\n",
    "wandb_logger = WandbLogger(project='car_classifier', log_model='all', resume=False)\n",
    "\n",
    "# Создание модели\n",
    "model = CarClassifierViT()\n",
    "\n",
    "data_module = DataModule()\n",
    "\n",
    "# Добавим сохранение чекпоинтов\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints',\n",
    "    filename='car-classifier-{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=3,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "# Создание тренера с wandb logger\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', patience=3),\n",
    "        checkpoint_callback\n",
    "    ],\n",
    "    gradient_clip_val=1.0  # Добавим клиппинг градиентов\n",
    ")\n",
    "    \n",
    "# Обучение модели\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytdml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
