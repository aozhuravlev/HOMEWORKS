{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import open_clip\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from sklearn.metrics import f1_score\n",
    "import pytorch_lightning as pl\n",
    "from seed import seed_everything\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(137)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = 8\n",
    "LR = 0.001\n",
    "DR = 0.2\n",
    "EPOCHS = 10\n",
    "NUM_CLASSES = 10\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43788/3892330222.py:24: UserWarning: Argument(s) 'max_holes, max_height, max_width, mask_fill_value' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(max_holes=1, max_height=10, max_width=12, mask_fill_value=0, p=0.5),\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Функция-обёртка для Albumentations\n",
    "class AlbumentationsTransform:\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, img):\n",
    "        try:\n",
    "            img = np.array(img)  # Преобразуем PIL.Image в numpy\n",
    "            augmented = self.transform(image=img)  # Передаём в albumentations\n",
    "            return augmented[\"image\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error in Albumentations transformation: {e}\")\n",
    "            return img  # Вернем изображение без изменений в случае ошибки\n",
    "\n",
    "\n",
    "# Определим преобразования с использованием albumentations\n",
    "transform_train = A.Compose([\n",
    "    A.HorizontalFlip(p=0.3),\n",
    "    A.Affine(scale=(0.7, 1.3), translate_percent=(0.1, 0.1), rotate=(-15, 15), p=0.5),\n",
    "    # A.RandomResizedCrop(size=(384, 384), scale=(0.8, 1.0), ratio=(0.9, 1.1), p=0.5),\n",
    "    A.CoarseDropout(max_holes=1, max_height=10, max_width=12, mask_fill_value=0, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.HueSaturationValue(p=0.3),\n",
    "    A.RandomGamma(p=0.3),\n",
    "    A.Resize(width=224, height=224),\n",
    "    A.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "transform_test = A.Compose([\n",
    "    A.Resize(width=224, height=224),\n",
    "    A.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261)),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=BATCH_SIZE, train_split=0.8):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_split = train_split\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "        \n",
    "    def setup(self, stage: str):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            full_dataset = datasets.ImageFolder(\n",
    "                root=\"./data/train/\",\n",
    "                transform=AlbumentationsTransform(transform_train)\n",
    "            )\n",
    "            train_size = int(self.train_split * len(full_dataset))\n",
    "            val_size = len(full_dataset) - train_size\n",
    "            self.train_dataset, self.val_dataset = random_split(\n",
    "                full_dataset, [train_size, val_size]\n",
    "            )\n",
    "\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.test_dataset = datasets.ImageFolder(\n",
    "                root=\"./data/test_upload/\",\n",
    "                transform=AlbumentationsTransform(transform_test)\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=True,\n",
    "            num_workers=NUM_WORKERS\n",
    "        ) if self.train_dataset else None\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=False,\n",
    "            num_workers=NUM_WORKERS\n",
    "        ) if self.val_dataset else None\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=NUM_WORKERS\n",
    "        ) if self.test_dataset else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import F1Score, Accuracy\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, stride=1, expansion=4, dropout_rate=DR\n",
    "    ):\n",
    "        super().__init__()\n",
    "        bottleneck_channels = out_channels // expansion\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, bottleneck_channels, kernel_size=1, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(bottleneck_channels)\n",
    "        self.dropout1 = nn.Dropout2d(p=dropout_rate)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            bottleneck_channels,\n",
    "            bottleneck_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(bottleneck_channels)\n",
    "        self.dropout2 = nn.Dropout2d(p=dropout_rate)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            bottleneck_channels, out_channels, kernel_size=1, bias=False\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        self.dropout3 = nn.Dropout2d(p=dropout_rate)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels, out_channels, kernel_size=1, stride=stride, bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout2(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.dropout3(out)\n",
    "\n",
    "        out += self.shortcut(residual)\n",
    "        return self.relu(out)\n",
    "\n",
    "\n",
    "class CarClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, learning_rate=LR, dropout_rate=DR):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.f1_score = F1Score(num_classes=num_classes, task=\"multiclass\")\n",
    "        # self.val_acc = Accuracy(num_classes=num_classes, task=\"multiclass\")\n",
    "\n",
    "        # Backbone with dropout\n",
    "        self.layer1 = BottleneckBlock(3, 64, stride=2, dropout_rate=dropout_rate)\n",
    "        self.layer2 = BottleneckBlock(64, 128, stride=2, dropout_rate=dropout_rate)\n",
    "        self.layer3 = BottleneckBlock(128, 256, stride=2, dropout_rate=dropout_rate)\n",
    "\n",
    "        # Classifier\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)  # Dropout перед полносвязным слоем\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)  # Применяем dropout перед классификацией\n",
    "        return self.fc(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.val_acc(preds, y)\n",
    "        f1 = self.f1_score(preds, y)\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_f1\", f1, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return {\"val_loss\": loss, \"val_f1\": f1}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": scheduler,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "\n",
    "# В основном скрипте обучения:\n",
    "def train_model():\n",
    "    # Инициализация wandb\n",
    "    wandb_logger = WandbLogger(project='car_classifier', log_model='all')\n",
    "    \n",
    "    # Создание модели\n",
    "    model = CarClassifier()\n",
    "\n",
    "    data_module = DataModule()\n",
    "    \n",
    "    # Создание тренера с wandb logger\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=10,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=3)],\n",
    "    )\n",
    "        \n",
    "    # Обучение модели\n",
    "    trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmoscowzhuravlev\u001b[0m (\u001b[33mmoscowzhuravlev-selfemployedalex\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250207_094934-bxhd1msw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier/runs/bxhd1msw' target=\"_blank\">lemon-jazz-11</a></strong> to <a href='https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier' target=\"_blank\">https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier/runs/bxhd1msw' target=\"_blank\">https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier/runs/bxhd1msw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | criterion | CrossEntropyLoss   | 0      | train\n",
      "1 | f1_score  | MulticlassF1Score  | 0      | train\n",
      "2 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "3 | layer1    | BottleneckBlock    | 3.9 K  | train\n",
      "4 | layer2    | BottleneckBlock    | 24.2 K | train\n",
      "5 | layer3    | BottleneckBlock    | 95.5 K | train\n",
      "6 | avgpool   | AdaptiveAvgPool2d  | 0      | train\n",
      "7 | flatten   | Flatten            | 0      | train\n",
      "8 | dropout   | Dropout            | 0      | train\n",
      "9 | fc        | Linear             | 2.6 K  | train\n",
      "---------------------------------------------------------\n",
      "126 K     Trainable params\n",
      "0         Non-trainable params\n",
      "126 K     Total params\n",
      "0.505     Total estimated model params size (MB)\n",
      "49        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92fe40ffe65416fbc7399f2b426625f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4b6a5d2c804ce49d682fe06c669ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('medium')\n",
    "train_model()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytdml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
