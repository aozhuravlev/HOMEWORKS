{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import open_clip\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import f1_score\n",
    "import pytorch_lightning as pl\n",
    "from seed import seed_everything\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(137)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 8\n",
    "LR = 0.001\n",
    "DR = 0.2\n",
    "EPOCHS = 10\n",
    "NUM_CLASSES = 10\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_size = (224, 224) \n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize(image_size),  # Изменение размера\n",
    "#     transforms.ToTensor()           # Преобразование в тензор\n",
    "# ])\n",
    "\n",
    "# # Датасет без нормализации\n",
    "# dataset = datasets.ImageFolder(root=\"./data/train/\", transform=transform)\n",
    "# loader = DataLoader(dataset, batch_size=128, shuffle=False, num_workers=8, persistent_workers=True)\n",
    "\n",
    "# # Инициализируем тензоры для хранения сумм и квадратов сумм\n",
    "# mean = torch.zeros(3)\n",
    "# std = torch.zeros(3)\n",
    "# total_images = 0\n",
    "\n",
    "# for images, _ in loader:\n",
    "#     # Количество изображений в текущем батче\n",
    "#     batch_size = images.size(0)\n",
    "#     # Суммируем значения по каналам\n",
    "#     mean += torch.mean(images, dim=[0, 2, 3]) * batch_size\n",
    "#     # Суммируем квадраты значений по каналам\n",
    "#     std += torch.std(images, dim=[0, 2, 3]) * batch_size\n",
    "#     # Общее количество изображений\n",
    "#     total_images += batch_size\n",
    "\n",
    "# # Усредняем по всему датасету\n",
    "# mean /= total_images\n",
    "# std /= total_images\n",
    "\n",
    "# print(\"Mean:\", mean.numpy()) # Mean: [0.48012924 0.4843966  0.49254295]\n",
    "# print(\"Std:\", std.numpy()) # Std: [0.2613408 0.263237  0.269442 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5645/191347543.py:23: UserWarning: Argument(s) 'max_holes, max_height, max_width, mask_fill_value' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(max_holes=1, max_height=10, max_width=12, mask_fill_value=0, p=0.5),\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Функция-обёртка для Albumentations\n",
    "class AlbumentationsTransform:\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, img):\n",
    "        try:\n",
    "            img = np.array(img)  # Преобразуем PIL.Image в numpy\n",
    "            augmented = self.transform(image=img)  # Передаём в albumentations\n",
    "            return augmented[\"image\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error in Albumentations transformation: {e}\")\n",
    "            return img  # Вернем изображение без изменений в случае ошибки\n",
    "\n",
    "\n",
    "# Определим преобразования с использованием albumentations\n",
    "transform_train = A.Compose([\n",
    "    A.HorizontalFlip(p=0.3),\n",
    "    A.Affine(scale=(0.7, 1.3), translate_percent=(0.1, 0.1), rotate=(-15, 15), p=0.5),\n",
    "    A.CoarseDropout(max_holes=1, max_height=10, max_width=12, mask_fill_value=0, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.HueSaturationValue(p=0.3),\n",
    "    A.RandomGamma(p=0.3),\n",
    "    A.Resize(width=224, height=224),\n",
    "    A.Normalize(mean=(0.4801, 0.4844, 0.4925), std=(0.261, 0.263, 0.269)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "transform_test = A.Compose([\n",
    "    A.Resize(width=224, height=224),\n",
    "    A.Normalize(mean=(0.4801, 0.4844, 0.4925), std=(0.261, 0.263, 0.269)),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=BATCH_SIZE, train_split=0.8):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_split = train_split\n",
    "        self.train_dataset = None\n",
    "        self.val_dataset = None\n",
    "        \n",
    "    def setup(self, stage: str):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            full_dataset = datasets.ImageFolder(\n",
    "                root=\"./data/train/\",\n",
    "                transform=AlbumentationsTransform(transform_train)\n",
    "            )\n",
    "            train_size = int(self.train_split * len(full_dataset))\n",
    "            val_size = len(full_dataset) - train_size\n",
    "            self.train_dataset, self.val_dataset = random_split(\n",
    "                full_dataset, [train_size, val_size]\n",
    "            )\n",
    "\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.test_dataset = datasets.ImageFolder(\n",
    "                root=\"./data/test_upload/\",\n",
    "                transform=AlbumentationsTransform(transform_test)\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=True,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            persistent_workers=True,\n",
    "        ) if self.train_dataset else None\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            shuffle=True,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            persistent_workers=True,\n",
    "        ) if self.val_dataset else None\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            persistent_workers=True,\n",
    "        ) if self.test_dataset else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BASE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import F1Score, Accuracy\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, stride=1, expansion=4, dropout_rate=DR\n",
    "    ):\n",
    "        super().__init__()\n",
    "        bottleneck_channels = out_channels // expansion\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, bottleneck_channels, kernel_size=1, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(bottleneck_channels)\n",
    "        self.dropout1 = nn.Dropout2d(p=dropout_rate)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            bottleneck_channels,\n",
    "            bottleneck_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(bottleneck_channels)\n",
    "        self.dropout2 = nn.Dropout2d(p=dropout_rate)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            bottleneck_channels, out_channels, kernel_size=1, bias=False\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        self.dropout3 = nn.Dropout2d(p=dropout_rate)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels, out_channels, kernel_size=1, stride=stride, bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout2(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.dropout3(out)\n",
    "\n",
    "        out += self.shortcut(residual)\n",
    "        return self.relu(out)\n",
    "\n",
    "\n",
    "class CarClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes=NUM_CLASSES, learning_rate=LR, dropout_rate=DR):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.f1_score = F1Score(num_classes=num_classes, task=\"multiclass\")\n",
    "        # self.val_acc = Accuracy(num_classes=num_classes, task=\"multiclass\")\n",
    "\n",
    "        # Backbone with dropout\n",
    "        self.layer1 = BottleneckBlock(3, 64, stride=2, dropout_rate=dropout_rate)\n",
    "        self.layer2 = BottleneckBlock(64, 128, stride=2, dropout_rate=dropout_rate)\n",
    "        self.layer3 = BottleneckBlock(128, 256, stride=2, dropout_rate=dropout_rate)\n",
    "\n",
    "        # Classifier\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)  # Dropout перед полносвязным слоем\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)  # Применяем dropout перед классификацией\n",
    "        return self.fc(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.val_acc(preds, y)\n",
    "        f1 = self.f1_score(preds, y)\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_f1\", f1, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return {\"val_loss\": loss, \"val_f1\": f1}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": scheduler,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "\n",
    "# В основном скрипте обучения:\n",
    "def train_model():\n",
    "    # Инициализация wandb\n",
    "    wandb_logger = WandbLogger(project='car_classifier', log_model='all')\n",
    "    \n",
    "    # Создание модели\n",
    "    model = CarClassifier()\n",
    "\n",
    "    data_module = DataModule()\n",
    "    \n",
    "    # Создание тренера с wandb logger\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=10,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=3)],\n",
    "    )\n",
    "        \n",
    "    # Обучение модели\n",
    "    trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmoscowzhuravlev\u001b[0m (\u001b[33mmoscowzhuravlev-selfemployedalex\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250207_094934-bxhd1msw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier/runs/bxhd1msw' target=\"_blank\">lemon-jazz-11</a></strong> to <a href='https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier' target=\"_blank\">https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier/runs/bxhd1msw' target=\"_blank\">https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier/runs/bxhd1msw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | criterion | CrossEntropyLoss   | 0      | train\n",
      "1 | f1_score  | MulticlassF1Score  | 0      | train\n",
      "2 | val_acc   | MulticlassAccuracy | 0      | train\n",
      "3 | layer1    | BottleneckBlock    | 3.9 K  | train\n",
      "4 | layer2    | BottleneckBlock    | 24.2 K | train\n",
      "5 | layer3    | BottleneckBlock    | 95.5 K | train\n",
      "6 | avgpool   | AdaptiveAvgPool2d  | 0      | train\n",
      "7 | flatten   | Flatten            | 0      | train\n",
      "8 | dropout   | Dropout            | 0      | train\n",
      "9 | fc        | Linear             | 2.6 K  | train\n",
      "---------------------------------------------------------\n",
      "126 K     Trainable params\n",
      "0         Non-trainable params\n",
      "126 K     Total params\n",
      "0.505     Total estimated model params size (MB)\n",
      "49        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92fe40ffe65416fbc7399f2b426625f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4b6a5d2c804ce49d682fe06c669ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('medium')\n",
    "train_model()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **FINE TUNED ViT-B-16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import open_clip\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import MulticlassF1Score, Accuracy\n",
    "\n",
    "class CarClassifierViT(pl.LightningModule):\n",
    "    def __init__(self, num_classes=10, lr=1e-3, freeze_backbone_epochs=3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Загружаем предобученную модель\n",
    "        self.model, _, _ = open_clip.create_model_and_transforms(\"ViT-B-16\", pretrained=\"openai\")\n",
    "        self.model.visual.proj = None  # Убираем ненужный projection\n",
    "        \n",
    "        # Меняем head (классификационный слой)\n",
    "        embed_dim = self.model.visual.ln_post.normalized_shape[0]\n",
    "        self.model.visual.head = nn.Linear(embed_dim, num_classes)\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.f1_score = MulticlassF1Score(num_classes=num_classes, average=\"macro\")\n",
    "        self.acc = Accuracy(num_classes=num_classes, task=\"multiclass\")\n",
    "        self.lr = lr\n",
    "        self.freeze_backbone_epochs = freeze_backbone_epochs\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.model.encode_image(x)  # Получаем эмбеддинги\n",
    "        logits = self.model.visual.head(features)  # Пропускаем через head\n",
    "        return logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = self.acc(preds, y)\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        f1 = self.f1_score(preds, y)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        self.log(\"val_f1\", f1, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.model.visual.head.parameters(), lr=self.lr)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def on_train_epoch_start(self):\n",
    "        if self.current_epoch == self.freeze_backbone_epochs:\n",
    "            for param in self.model.visual.parameters():\n",
    "                param.requires_grad = True\n",
    "            optimizer = self.optimizers()\n",
    "            backbone_params = set(self.model.visual.parameters())\n",
    "            existing_params = set(p for group in optimizer.param_groups for p in group['params'])\n",
    "            new_params = backbone_params - existing_params\n",
    "            if new_params:\n",
    "                optimizer.add_param_group({\"params\": list(new_params), \"lr\": self.lr * 0.1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "\n",
    "# В основном скрипте обучения:\n",
    "def train_model():\n",
    "\n",
    "    torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "    # Инициализация wandb\n",
    "    wandb_logger = WandbLogger(project='car_classifier', log_model='all')\n",
    "    \n",
    "    # Создание модели\n",
    "    model = CarClassifierViT()\n",
    "\n",
    "    data_module = DataModule()\n",
    "    \n",
    "    # Создание тренера с wandb logger\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=1,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=3)],\n",
    "    )\n",
    "        \n",
    "    # Обучение модели\n",
    "    trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/miniconda3/envs/pytdml/lib/python3.10/site-packages/open_clip/factory.py:380: UserWarning: These pretrained weights were trained with QuickGELU activation but the model config does not have that enabled. Consider using a model config with a \"-quickgelu\" suffix or enable with a flag.\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmoscowzhuravlev\u001b[0m (\u001b[33mmoscowzhuravlev-selfemployedalex\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250207_120321-m76vkdng</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier/runs/m76vkdng' target=\"_blank\">firm-serenity-18</a></strong> to <a href='https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier' target=\"_blank\">https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier/runs/m76vkdng' target=\"_blank\">https://wandb.ai/moscowzhuravlev-selfemployedalex/car_classifier/runs/m76vkdng</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model     | CLIP               | 149 M  | train\n",
      "1 | criterion | CrossEntropyLoss   | 0      | train\n",
      "2 | f1_score  | MulticlassF1Score  | 0      | train\n",
      "3 | acc       | MulticlassAccuracy | 0      | train\n",
      "---------------------------------------------------------\n",
      "149 M     Trainable params\n",
      "0         Non-trainable params\n",
      "149 M     Total params\n",
      "596.941   Total estimated model params size (MB)\n",
      "280       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ac57c85d164a6292d426db133d7146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/miniconda3/envs/pytdml/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a0adb824684c13bf3c3eb35aacf6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7496aaf6903246b68bb3830089e53211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9438bc481ea94036882991f2a091dc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3fef82bbdb4db6b99647c43ce1b212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0a05ba600e4d5695fb37d13530fa8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243e6915f851475e85e9ec58b9b8e33e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981edc9512d7481a875e98d9f35af346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'wandb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/alex/HOMEWORKS/DL/05_FT_TL/05_FT.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/alex/HOMEWORKS/DL/05_FT_TL/05_FT.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_model()\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/alex/HOMEWORKS/DL/05_FT_TL/05_FT.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m wandb\u001b[39m.\u001b[39mfinish()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wandb' is not defined"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytdml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
